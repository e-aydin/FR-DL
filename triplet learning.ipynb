{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1f9c70ca-d84e-4c0d-931b-6aadff57e499",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cbf1a947-fbf8-4bda-b28e-35fbc5487e12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_and_preprocess_dataset(dataset_folder):\n",
    "    image_data = []\n",
    "    person_folders = sorted(os.listdir(dataset_folder))\n",
    "\n",
    "    for person_folder in person_folders:\n",
    "        person_path = os.path.join(dataset_folder, person_folder)\n",
    "        if os.path.isdir(person_path):\n",
    "            image_paths = sorted(os.listdir(person_path))\n",
    "            for image_name in image_paths:\n",
    "                image_path = os.path.join(person_path, image_name)\n",
    "                img = load_img(image_path, target_size=(128, 128))\n",
    "                img = img_to_array(img) / 255.0\n",
    "                try:\n",
    "                    image = Image.open(image_path)\n",
    "                except OSError:\n",
    "                    continue\n",
    "                image_data.append(img)\n",
    "\n",
    "    return np.array(image_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "17433c22-7721-4d51-9aae-16e4a7b51659",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_triplets(data, num_triplets=10000):\n",
    "    triplets = []\n",
    "    for _ in range(num_triplets):\n",
    "        anchor_idx = np.random.randint(0, data.shape[0])\n",
    "        positive_idx = np.random.randint(0, data.shape[0])\n",
    "        while positive_idx == anchor_idx:\n",
    "            positive_idx = np.random.randint(0, data.shape[0])\n",
    "        negative_idx = np.random.randint(0, data.shape[0])\n",
    "        while negative_idx == anchor_idx or negative_idx == positive_idx:\n",
    "            negative_idx = np.random.randint(0, data.shape[0])\n",
    "        triplets.append([data[anchor_idx], data[positive_idx], data[negative_idx]])\n",
    "    return np.array(triplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "23322dc9-5c99-4e00-a804-74ae1295e135",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_base_network(input_shape):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=input_shape),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(128, activation='relu')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2888b064-53a3-4cb0-92e3-0c49a1ed2ab1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_test_triplets(data):\n",
    "    triplets = []\n",
    "    for _ in range(data.shape[0]):\n",
    "        anchor_idx = np.random.randint(0, data.shape[0])\n",
    "        positive_idx = np.random.randint(0, data.shape[0])\n",
    "        while positive_idx == anchor_idx:\n",
    "            positive_idx = np.random.randint(0, data.shape[0])\n",
    "        negative_idx = np.random.randint(0, data.shape[0])\n",
    "        while negative_idx == anchor_idx or negative_idx == positive_idx:\n",
    "            negative_idx = np.random.randint(0, data.shape[0])\n",
    "        triplets.append([data[anchor_idx], data[positive_idx], data[negative_idx]])\n",
    "    return np.array(triplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "03d60d88-d7d4-441c-a652-ac88557dacce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_and_compile_model(input_shape):\n",
    "    base_network = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "    ])\n",
    "\n",
    "    anchor_input = tf.keras.layers.Input(input_shape, name='anchor_input')\n",
    "    positive_input = tf.keras.layers.Input(input_shape, name='positive_input')\n",
    "    negative_input = tf.keras.layers.Input(input_shape, name='negative_input')\n",
    "\n",
    "    encoded_anchor = base_network(anchor_input)\n",
    "    encoded_positive = base_network(positive_input)\n",
    "    encoded_negative = base_network(negative_input)\n",
    "\n",
    "    merged_output = tf.keras.layers.concatenate([encoded_anchor, encoded_positive, encoded_negative], axis=-1)\n",
    "\n",
    "    # Normalize the output embedding vectors\n",
    "    merged_output = tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=-1))(merged_output)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=[anchor_input, positive_input, negative_input], outputs=merged_output)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss=triplet_loss)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "88214d56-f190-420a-ac4e-309a0cc9e406",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_folder = '1/lfw-deepfunneled/lfw-deepfunneled/'\n",
    "image_data = load_and_preprocess_dataset(dataset_folder)\n",
    "\n",
    "# Generate triplets for training\n",
    "num_triplets = 10000\n",
    "triplets_train = generate_triplets(image_data, num_triplets=num_triplets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fa0d9ce4-0d8a-45cf-a200-f9ee7b263475",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(triplets_train, test_size=0.2)\n",
    "\n",
    "dummy_labels_train = np.zeros((train_data.shape[0], 1))\n",
    "dummy_labels_val = np.zeros((val_data.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7bd66a0d-a7dd-4c76-b799-66d1acbb1d2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def triplet_loss(y_true, y_pred, alpha=0.2):\n",
    "    anchor, positive, negative = y_pred[:, :128], y_pred[:, 128:256], y_pred[:, 256:]\n",
    "    pos_dist = tf.reduce_sum(tf.square(anchor - positive), axis=-1)\n",
    "    neg_dist = tf.reduce_sum(tf.square(anchor - negative), axis=-1)\n",
    "    basic_loss = pos_dist - neg_dist + alpha\n",
    "    loss = tf.reduce_sum(tf.maximum(basic_loss, 0.0))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "95a44877-335d-4f4d-a2e1-a38d90c15c03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_and_preprocess_test_dataset(test_folder):\n",
    "    test_image_data = []\n",
    "    test_labels = []\n",
    "\n",
    "    person_folders = sorted(os.listdir(test_folder))\n",
    "    \n",
    "    for person_folder in person_folders:\n",
    "        person_path = os.path.join(test_folder, person_folder)\n",
    "        if os.path.isdir(person_path):\n",
    "            image_paths = sorted(os.listdir(person_path))\n",
    "            for image_name in image_paths:\n",
    "                image_path = os.path.join(person_path, image_name)\n",
    "                img = load_img(image_path, target_size=(128, 128))\n",
    "                img = img_to_array(img) / 255.0\n",
    "                test_image_data.append(img)\n",
    "                test_labels.append(person_folder)  # Assuming folder names are the labels\n",
    "\n",
    "    return np.array(test_image_data), np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a86186d9-de0b-47b2-a409-df850246f9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (128, 128, 3)\n",
    "model = create_and_compile_model(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "713524ee-d25d-4812-8393-ac74827e6e61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tensorboard_callback = TensorBoard(log_dir='./logs', histogram_freq=1, write_graph=True, write_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6b90ee66-6f54-42a1-b816-5f43ca6743b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "125/125 [==============================] - 30s 232ms/step - loss: 12.7830 - val_loss: 12.7387\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 22s 176ms/step - loss: 12.7776 - val_loss: 12.7415\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 16s 126ms/step - loss: 12.8007 - val_loss: 12.7297\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 19s 154ms/step - loss: 12.7516 - val_loss: 12.7286\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 17s 134ms/step - loss: 12.7689 - val_loss: 12.7442\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 15s 120ms/step - loss: 12.7346 - val_loss: 12.7313\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 14s 116ms/step - loss: 12.6925 - val_loss: 12.7296\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 13s 105ms/step - loss: 12.8033 - val_loss: 12.7374\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 15s 122ms/step - loss: 12.7464 - val_loss: 12.7269\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 13s 104ms/step - loss: 12.6824 - val_loss: 12.7897\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22afa7cbdc0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    [train_data[:, 0], train_data[:, 1], train_data[:, 2]],\n",
    "    dummy_labels_train,\n",
    "    validation_data=([val_data[:, 0], val_data[:, 1], val_data[:, 2]], dummy_labels_val),\n",
    "    epochs=10,\n",
    "    batch_size=64,\n",
    "    callbacks=[tensorboard_callback]  # TensorBoard callback ekleniyor\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f827e3c5-d6bf-441c-ba95-fea7e938b38b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 1s 11ms/step - loss: 6.3809\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6.380923271179199"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_folder = '1/lfw-deepfunneled/test/'\n",
    "test_image_data, test_labels = load_and_preprocess_test_dataset(test_folder)\n",
    "\n",
    "# Generate triplets for testing\n",
    "test_triplets = generate_test_triplets(test_image_data)\n",
    "\n",
    "dummy_labels_test = np.zeros((test_triplets.shape[0], 1))\n",
    "# Evaluate the model on the test set\n",
    "model.evaluate([test_triplets[:, 0], test_triplets[:, 1], test_triplets[:, 2]], dummy_labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "814e2c52-8666-4ca8-b17e-7404418f0659",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-753b836fdf41b2a4\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-753b836fdf41b2a4\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0244f327-a27f-431a-b444-b951e57939f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No such layer: sequential. Existing layers are: ['anchor_input', 'positive_input', 'negative_input', 'sequential_2', 'concatenate_1', 'lambda'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m input_img \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(input_img, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Add batch dimension\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Extract embeddings for the input image\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m input_embedding \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msequential\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m(input_img)  \u001b[38;5;66;03m# 'sequential' is the name of your base network\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Calculate distances\u001b[39;00m\n\u001b[0;32m     11\u001b[0m distances \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfradeon\\lib\\site-packages\\keras\\engine\\training.py:3275\u001b[0m, in \u001b[0;36mModel.get_layer\u001b[1;34m(self, name, index)\u001b[0m\n\u001b[0;32m   3273\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m layer\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m name:\n\u001b[0;32m   3274\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m layer\n\u001b[1;32m-> 3275\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   3276\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such layer: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Existing layers are: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3277\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(layer\u001b[38;5;241m.\u001b[39mname\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mlayer\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3278\u001b[0m     )\n\u001b[0;32m   3279\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   3280\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProvide either a layer name or layer index at \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`get_layer`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3281\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: No such layer: sequential. Existing layers are: ['anchor_input', 'positive_input', 'negative_input', 'sequential_2', 'concatenate_1', 'lambda']."
     ]
    }
   ],
   "source": [
    "# Load and preprocess the input image\n",
    "input_image_path = 'C:/Users/enver/Desktop/giris/11.jpg'\n",
    "input_img = load_img(input_image_path, target_size=(128, 128))\n",
    "input_img = img_to_array(input_img) / 255.0\n",
    "input_img = np.expand_dims(input_img, axis=0)  # Add batch dimension\n",
    "\n",
    "# Extract embeddings for the input image\n",
    "input_embedding = model.get_layer('sequential')(input_img)  # 'sequential' is the name of your base network\n",
    "\n",
    "# Calculate distances\n",
    "distances = []\n",
    "for i in range(test_image_data.shape[0]):\n",
    "    test_embedding = model.get_layer('sequential')(np.expand_dims(test_image_data[i], axis=0))\n",
    "    distance = np.linalg.norm(input_embedding - test_embedding)\n",
    "    distances.append(distance)\n",
    "\n",
    "# Convert distances to numpy array for sorting\n",
    "distances = np.array(distances)\n",
    "\n",
    "# Sort and select top k indices\n",
    "k = 5  # You can adjust k as needed\n",
    "top_k_indices = np.argsort(distances)[:k]\n",
    "\n",
    "# Display the top k similar images\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for index in top_k_indices:\n",
    "    similar_image = test_image_data[index]\n",
    "    plt.imshow(similar_image)\n",
    "    plt.title(f'Distance: {distances[index]:.4f}')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801c33f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
